{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloud.google.com/blog/products/gcp/new-in-tensorflow-14-converting-a-keras-model-to-a-tensorflow-estimator\n",
    "https://github.com/tensorflow/workshops/blob/master/extras/keras-to-estimator/keras-to-estimator.ipynb\n",
    "\n",
    "## Stack over flow user post classification\n",
    "### Kerasto estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have TensorFlow version 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from os.path import expanduser\n",
    "\n",
    "# This code was tested with TensorFlow v1.4\n",
    "print(\"You have TensorFlow version\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv\n",
    "\n",
    "home = expanduser(\"~\")\n",
    "print(home)\n",
    "\n",
    "data = pd.read_csv(home + \"/.keras/stack-overflow-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is causing this behavior  in our c# datet...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have dynamic html load as if it was in an ifra...</td>\n",
       "      <td>asp.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to convert a float value in to min:sec  i ...</td>\n",
       "      <td>objective-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net framework 4 redistributable  just wonderi...</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trying to calculate and print the mean and its...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post         tags\n",
       "0  what is causing this behavior  in our c# datet...           c#\n",
       "1  have dynamic html load as if it was in an ifra...      asp.net\n",
       "2  how to convert a float value in to min:sec  i ...  objective-c\n",
       "3  .net framework 4 redistributable  just wonderi...         .net\n",
       "4  trying to calculate and print the mean and its...       python"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective-c      2000\n",
       "ruby-on-rails    2000\n",
       "jquery           2000\n",
       "angularjs        2000\n",
       "javascript       2000\n",
       "c                2000\n",
       "java             2000\n",
       "mysql            2000\n",
       "sql              2000\n",
       "iphone           2000\n",
       "python           2000\n",
       ".net             2000\n",
       "asp.net          2000\n",
       "c++              2000\n",
       "c#               2000\n",
       "html             2000\n",
       "android          2000\n",
       "ios              2000\n",
       "php              2000\n",
       "css              2000\n",
       "Name: tags, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that we have a balanced dataset\n",
    "# Note: data was randomly shuffled in our BigQuery query\n",
    "data['tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 32000\n",
      "Test size: 8000\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "train_size = int(len(data) * .8)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(data) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_posts = data['post'][:train_size]\n",
    "train_tags = data['tags'][:train_size]\n",
    "\n",
    "test_posts = data['post'][train_size:]\n",
    "test_tags = data['tags'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = keras.preprocessing.text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts).astype(np.float32) # model expects float32\n",
    "x_test = tokenize.texts_to_matrix(test_posts).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn utility to convert label strings to numbered index\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the labels to a one-hot representation\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes).astype(np.float32)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (32000, 1000)\n",
      "x_test shape: (8000, 1000)\n",
      "y_train shape: (32000, 20)\n",
      "y_test shape: (8000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model trains very quickly and 2 epochs are already more than enough\n",
    "# Training for more epochs will likely lead to overfitting on this dataset\n",
    "# You can try tweaking these hyperparamaters when using this model with your own data\n",
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(512, input_shape=(max_words,), name=\"posts\"))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(num_classes))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpCxB_WY\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f18ada22d50>, '_model_dir': '/tmp/tmpCxB_WY', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Convert Keras model to estimator\n",
    "estimator_model = keras.estimator.model_to_estimator(keras_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input fn\n",
    "def input_function(features, labels=None, shuffle=False):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"posts_input\": features}, # See the accompanying blog post for explanation on naming\n",
    "        y=labels,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpCxB_WY/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('/tmp/tmpCxB_WY/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: posts/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: posts/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpCxB_WY/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.1025286, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.9935193, step = 0 (1.287 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.67278653, step = 0 (1.415 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:Loss for final step: 0.5882633.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f18ad1b4750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_model.train(input_fn=input_function(x_train, y_train, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-05-15:48:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpCxB_WY/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-05-15:48:20\n",
      "INFO:tensorflow:Saving dict for global step 0: accuracy = 0.048487104, global_step = 0, loss = 3.0422518\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 0: /tmp/tmpCxB_WY/model.ckpt-0\n",
      "{'loss': 3.0422518, 'global_step': 0, 'accuracy': 0.048487104}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy of our trained model\n",
    "score = estimator_model.evaluate(input_function(x_test, labels=y_test))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpCxB_WY/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Actual label:jquery\n",
      "Predicted label: ios\n",
      "\n",
      "Actual label:.net\n",
      "Predicted label: objective-c\n",
      "\n",
      "Actual label:android\n",
      "Predicted label: objective-c\n",
      "\n",
      "Actual label:c++\n",
      "Predicted label: jquery\n",
      "\n",
      "Actual label:.net\n",
      "Predicted label: iphone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's how to generate a prediction on individual examples\n",
    "text_labels = encoder.classes_ \n",
    "\n",
    "# We'll make predictions for the first five examples\n",
    "examples = x_test[:5]\n",
    "predictions = list(estimator_model.predict(input_function(examples)))\n",
    "\n",
    "# Print out the true and expected label\n",
    "for i in range(len(examples)):\n",
    "    prediction_array = list(predictions[i].values())[0]\n",
    "    predicted_label = text_labels[np.argmax(prediction_array)]\n",
    "    print('Actual label:' + test_tags.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
